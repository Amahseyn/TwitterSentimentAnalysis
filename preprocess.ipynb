{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  ProductName    Result  \\\n",
      "0      2401  Borderlands  Positive   \n",
      "1      2401  Borderlands  Positive   \n",
      "2      2401  Borderlands  Positive   \n",
      "3      2401  Borderlands  Positive   \n",
      "4      2401  Borderlands  Positive   \n",
      "...     ...          ...       ...   \n",
      "74676  9200       Nvidia  Positive   \n",
      "74677  9200       Nvidia  Positive   \n",
      "74678  9200       Nvidia  Positive   \n",
      "74679  9200       Nvidia  Positive   \n",
      "74680  9200       Nvidia  Positive   \n",
      "\n",
      "                                                 Message  \n",
      "0      I am coming to the borders and I will kill you...  \n",
      "1      im getting on borderlands and i will kill you ...  \n",
      "2      im coming on borderlands and i will murder you...  \n",
      "3      im getting on borderlands 2 and i will murder ...  \n",
      "4      im getting into borderlands and i can murder y...  \n",
      "...                                                  ...  \n",
      "74676  Just realized that the Windows partition of my...  \n",
      "74677  Just realized that my Mac window partition is ...  \n",
      "74678  Just realized the windows partition of my Mac ...  \n",
      "74679  Just realized between the windows partition of...  \n",
      "74680  Just like the windows partition of my Mac is l...  \n",
      "\n",
      "[74681 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filepath = \"twitter_training.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df.columns = [\"ID\",\"ProductName\",\"Result\",\"Message\"]\n",
    "# for i,x in enumerate(columnslist):\n",
    "#     df[x]=df.iloc[:,i]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74681 entries, 0 to 74680\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           74681 non-null  int64 \n",
      " 1   ProductName  74681 non-null  object\n",
      " 2   Result       74681 non-null  object\n",
      " 3   Message      73995 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28883/4275168532.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "df['Message'] = df['Message'].astype(str)\n",
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define a regex pattern to match URLs\n",
    "url_pattern = re.compile(r'https?://\\S+')\n",
    "\n",
    "# Define a function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "# Apply the function to the 'text' column and create a new column 'clean_text'\n",
    "df['Message'] = df['Message'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "df = df.replace(to_replace=r'\\d', value='', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/mio/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#nltk.download('punkt_tab')\n",
    "df['Message'] = df['Message'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Define a function to perform stemming on the 'text' column\n",
    "def stem_words(words):\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "# Define a function to perform stemming on the 'text' column\n",
    "def stem_words(words):\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "# Apply the function to the 'text' column and create a new column 'stemmed_text'\n",
    "df['stemmed_messages'] = df['Message'].apply(stem_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
